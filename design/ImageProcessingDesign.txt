ImageProcessingDesign:
======================
This document covers the design of the AGSE software and all relevant information


Motivation for Image Processing:
--------------------------------
Given (1) the prevalence of cameras and imaging hardware, which has (2) further increased the availability of high-performance image processing hardware and software, and (3) the versatility provided by imaging-based sensing, we have chosen to use a camera combined with image processing hardware and software as the base of the sample detection subsystem of the AGSE.  This camera integrates directly with our main processing board, the NVIDIA Jetson TK1.  Furthermore the Jetson, designed to add high fidelity image processing to robotics applications, contains 192 parallel GPU cores which support both OpenGL and CUDA parallel programming and image processing applications. Parallel image processing, segmentation, and object detection algorithms have been heavily researched and developed using both CUDA and OpenGL, and provide us with a large base of users and application code.  


Sample Description:
-------------------
The sample will be of an overall cylindrical shape. When viewed from all unoccluded non-coaxial angles, the sample will have as part of its defining shape outline two straight lines.  These lines' relative angle, theta, will converge to 0 (parallel) as phi, the angle between the view vector and the sample axial vector, approaches PI/2.  At all other angles the lines' infinite extrusions will intersect and produce theta.  Theta in image space provides the system with enough information to create the inverse perspective transform, which produces from theta the camera-space phi, providing the angle between the camera and the sample's axial vector.  

Furthermore, we can optionally improve the sample detection by making one of two assumptions about the color of the sample.  Either we can assume the sample to be of uniform diffuse color, or we can assume the sample to have some defined pattern to the color of its surface.  


Relevant Object Detection Methods:
----------------------------------
The main classes of image-based object detection and segmentation we have available utilize as their base functions one or more of the following: (1) color segmentation, (2) depth segmentation, (3) edge sementation, (4) line segmentation.  Color segmentation in its basic form assumes that an object has a uniform diffuse color which is distinct from the background of the image.  Depth Segmentation in its basic form asssumes that an object has a uniform perceived depth or perceived depth profile which is distinct from the background depth or depth profile of the image.  Edge segmenation in its basic form segments the image using a combination of color and contrast and produces edges between each segment of the image.  Line Segmentation can be an extension of edge segmentation which filters out all segment edges whose straight lengths fall below some threshold. 


Chosen Object Detection Algorithms:
-----------------------------------
Given the image-space sample description provided above, we have chosen to use line segmentation as the base of the sample detection software subsystem of the AGSE.  Additionally, given the two possible assumptions that can be made about the sample's diffuse color, we can integrate color based object detection based on a color profile for the sample.  This technique can be utilized to check that the screen-space area between two detected lines conforms to the sample's color profile (which may be a pattern or solid color), and therefore provide a higher degree of confidence for sample detection.  


Algorithm I/O:
--------------
The edge detection and color segmentation algorithms both take as input the raw camera image sample.  The output of the edge detection algorithm is a binary image where any non-zero value marks an edge between two different segments of the image.  The output of the color segmentation is a segmented image in which all pixels of a detected object (of a certain color or color profile) are replaced with the color or color profile of the object.  The output of the edge detection algorithm is used as the input of the line detection algorithm.  The line detection algorithm outputs the same type of binary image, except any non-straight edges falling below a certain straight-ness threshold have been filtered out.  


Modifications to OTS Algorithms:
--------------------------------
Because there maybe be occluding objects in the sample detection space, such as rocks, grass, or possibly man-made objects, we may, for improved sample detection capability and more versatility with respect to sample location, modify the chosen sample detection algorithms described above.  Such a modification may include changing how the results from the different (orthogonal) sample detection algorithms are weighed in the calculation of the detection confidence.  Alternatively, the modification may be adapting the off-the-shelf (OTS) algorithms to adjust their internal parameters for line/object segmentation.  Such modifications may be required in the case of large numbers of partially occluding objects or in the case of large changes in contrast or light in the captured images.  Finally, these modifications can be autonomously integrated into a state-machine which reconfigures these parameters to provide the highest sample detection confidence.  